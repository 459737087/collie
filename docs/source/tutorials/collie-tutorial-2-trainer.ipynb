{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3b7df9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp; 2 &ensp; CoLLiE 的使用案例\n",
    "\n",
    "&emsp; &emsp; 2.1 &ensp; 案例：指令微调 MOSS\n",
    "\n",
    "&emsp; &emsp; 2.2 &ensp; CoLLiE 的 Config 模块\n",
    "\n",
    "&emsp; &emsp; 2.3 &ensp; CoLLiE 的 Trainer 模块\n",
    "\n",
    "&emsp; &emsp; 2.4 &ensp; CoLLiE 的 Metric 模块\n",
    "\n",
    "&emsp; &emsp; 2.5 &ensp; CoLLiE 的 Monitor 模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb9260",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. &ensp; CoLLiE 的使用案例\n",
    "\n",
    "### 2.1 &ensp; 案例：指令微调 MOSS\n",
    "\n",
    "&ensp; &ensp; 在上一章中，我们已经介绍了 CoLLiE 提出的背景、实现的功能 以及 包含的模块。\n",
    "\n",
    "&ensp; &ensp; 写个LOMO、ZeRO3、微调MOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf770de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2023-06-30 20:46:28,132] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-06-30 20:46:28,133] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-06-30 20:46:28,135] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-06-30 20:46:28,136] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "\n",
      "===================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      " Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues \n",
      "and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "bin bin/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so \n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "bin /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "Fetching 17 files: 100%|██████████████████████| 17/17 [00:00<00:00, 8509.75it/s]\n",
      "[2023-06-30 20:46:41,782] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-06-30 20:46:41,782] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "Fetching 17 files: 100%|██████████████████████| 17/17 [00:00<00:00, 6891.86it/s]\n",
      "[2023-06-30 20:46:41,864] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-06-30 20:46:41,864] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-06-30 20:46:41,864] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "Fetching 17 files: 100%|██████████████████████| 17/17 [00:00<00:00, 6916.59it/s]\n",
      "[2023-06-30 20:46:41,988] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-06-30 20:46:41,989] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "Fetching 17 files: 100%|██████████████████████| 17/17 [00:00<00:00, 7035.34it/s]\n",
      "[2023-06-30 20:46:42,784] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-06-30 20:46:42,784] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-06-30 20:46:49,341] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 16.72B parameters\n",
      "\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m72.47 s/it.\u001B[0m \u001B[33m0:05:11\u001B[0m / \u001B[36m0:00:00\u001B[0m  \u001B[36m0:01:06\u001B[0m m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[35m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[90m━\u001B[0m\u001B[35m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m\u001B[91m━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m /  \u001B[2;36m[20:52:28]\u001B[0m\u001B[2;36m \u001B[0m\u001B[31mWARNING \u001B[0m The world size is not equal to the product of \u001B]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py\u001B\\\u001B[2mtrainer.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py#262\u001B\\\u001B[2m262\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         the parallel sizes set.\u001B[1;36m4\u001B[0m != \u001B[1;36m1\u001B[0m * \u001B[1;36m1\u001B[0m * \u001B[1;36m1\u001B[0m.        \u001B[2m              \u001B[0m\n",
      "\u001B[2;36m          \u001B[0m\u001B[2;36m \u001B[0m\u001B[31mWARNING \u001B[0m Set dp_size to \u001B[1;36m4\u001B[0m.                             \u001B]8;id=571858;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py\u001B\\\u001B[2mtrainer.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=91161;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py#265\u001B\\\u001B[2m265\u001B[0m\u001B]8;;\u001B\\\n",
      "[2023-06-30 20:52:28,457] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-06-30 20:52:28,457] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-30 20:52:28,616] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2023-06-30 20:52:28,616] [INFO] [utils.py:786:see_memory_usage] MA 7.93 GB         Max_MA 11.3 GB         CA 13.06 GB         Max_CA 13 GB \n",
      "[2023-06-30 20:52:28,617] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.89 GB, percent = 7.9%\n",
      "Parameter Offload: Total persistent parameters: 1474560 in 138 params\n",
      "[2023-06-30 20:52:28,736] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2023-06-30 20:52:28,737] [INFO] [utils.py:786:see_memory_usage] MA 7.93 GB         Max_MA 7.93 GB         CA 13.06 GB         Max_CA 13 GB \n",
      "[2023-06-30 20:52:28,737] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.89 GB, percent = 7.9%\n",
      "[2023-06-30 20:52:28,738] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-06-30 20:52:28,738] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-06-30 20:52:28,738] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-06-30 20:52:28,738] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcb5d7f5880>\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-06-30 20:52:28,739] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   fp16_auto_cast ............... False\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-06-30 20:52:28,740] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-06-30 20:52:28,770] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-06-30 20:52:28,770] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-06-30 20:52:28,770] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-06-30 20:52:28,770] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-06-30 20:52:28,770] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-06-30 20:52:28,770] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   steps_per_print .............. 10\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   train_batch_size ............. 8\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  2\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   world_size ................... 4\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. False\n",
      "[2023-06-30 20:52:28,771] [INFO] [config.py:964:print]   zero_optimization_stage ...... 3\n",
      "[2023-06-30 20:52:28,772] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true, \n",
      "    \"zero_force_ds_cpu_optimizer\": false, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }\n",
      "    }, \n",
      "    \"train_micro_batch_size_per_gpu\": 2, \n",
      "    \"gradient_accumulation_steps\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2KTraining Epoch   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "Training Batch: 0 / 13 \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m Gradient overflow, skipping step 0\n",
      "Gradient overflow, skipping step 0\n",
      "Gradient overflow, skipping step 0\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, \n",
      "reducing to 2147483648\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 0━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:15\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:15\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 0 / 13 \u001B[35m  8%\u001B[0m \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:15\u001B[0m / \u001B[36m-:--:--\u001B[0m Loss: 5.8789Gradient overflow, skipping step 1\n",
      "Gradient overflow, skipping step 1\n",
      "Gradient overflow, skipping step 1\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, \n",
      "reducing to 1073741824\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:15\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 1m\u001B[90m━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:15\u001B[0m / \u001B[36m-:--:--\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:15\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[31m-- it./s\u001B[0m \u001B[33m0:00:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 1 / 13 \u001B[35m 15%\u001B[0m \u001B[91m━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:22\u001B[0m / \u001B[36m0:01:24\u001B[0m Loss: 5.8789Gradient overflow, skipping step 2\n",
      "Gradient overflow, skipping step 2Gradient overflow, skipping step 2\n",
      "\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, \n",
      "reducing to 536870912\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 2m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:22\u001B[0m / \u001B[36m0:01:24\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:30\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:30\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 2 / 13 \u001B[35m 23%\u001B[0m \u001B[91m━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:30\u001B[0m / \u001B[36m0:01:15\u001B[0m Loss: 5.8789Gradient overflow, skipping step 3\n",
      "Gradient overflow, skipping step 3\n",
      "Gradient overflow, skipping step 3\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing\n",
      "to 268435456\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:30\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 30m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:30\u001B[0m / \u001B[36m0:01:15\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:30\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:37\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:37\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 3 / 13 \u001B[35m 31%\u001B[0m \u001B[91m━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:37\u001B[0m / \u001B[36m0:01:07\u001B[0m Loss: 5.8789Gradient overflow, skipping step 4\n",
      "Gradient overflow, skipping step 4\n",
      "Gradient overflow, skipping step 4\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing\n",
      "to 134217728\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:37\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 4[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:37\u001B[0m / \u001B[36m0:01:07\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:37\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 4 / 13 \u001B[35m 38%\u001B[0m \u001B[91m━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:44\u001B[0m / \u001B[36m0:01:00\u001B[0m Loss: 5.8789Gradient overflow, skipping step 5\n",
      "Gradient overflow, skipping step 5\n",
      "Gradient overflow, skipping step 5\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing\n",
      "to 67108864\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 5[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:44\u001B[0m / \u001B[36m0:01:00\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:52\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:52\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 5 / 13 \u001B[35m 46%\u001B[0m \u001B[91m━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:52\u001B[0m / \u001B[36m0:00:52\u001B[0m Loss: 5.8789Gradient overflow, skipping step 6\n",
      "Gradient overflow, skipping step 6\n",
      "Gradient overflow, skipping step 6\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing \n",
      "to 33554432\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:52\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 6\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:00:52\u001B[0m / \u001B[36m0:00:52\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:52\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:59\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:59\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 6 / 13 \u001B[35m 54%\u001B[0m \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:00:59\u001B[0m / \u001B[36m0:00:45\u001B[0m Loss: 5.8789Gradient overflow, skipping step 7\n",
      "Gradient overflow, skipping step 7\n",
      "Gradient overflow, skipping step 7\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing \n",
      "to 16777216\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:59\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 7━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:00:59\u001B[0m / \u001B[36m0:00:45\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:00:59\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:07\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:07\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch: 7 / 13 \u001B[35m 62%\u001B[0m \u001B[91m━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:07\u001B[0m / \u001B[36m0:00:37\u001B[0m Loss: 5.8789Gradient overflow, skipping step 8\n",
      "Gradient overflow, skipping step 8\n",
      "Gradient overflow, skipping step 8\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing \n",
      "to 8388608\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:07\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 8━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:07\u001B[0m / \u001B[36m0:00:37\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:07\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:14\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:14\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 8 / 13 \u001B[35m 69%\u001B[0m \u001B[91m━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:14\u001B[0m / \u001B[36m0:00:30\u001B[0m Loss: 5.8789Gradient overflow, skipping step 9Gradient overflow, skipping step 9\n",
      "\n",
      "Gradient overflow, skipping step 9\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing \n",
      "to 4194304\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:14\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 9━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:14\u001B[0m / \u001B[36m0:00:30\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:14\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 9 / 13 \u001B[35m 77%\u001B[0m \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:01:22\u001B[0m / \u001B[36m0:00:23\u001B[0m Loss: 5.8789Gradient overflow, skipping step 10\n",
      "Gradient overflow, skipping step 10\n",
      "Gradient overflow, skipping step 10\n",
      "\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing \n",
      "to 2097152\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 10━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[31m0.13 it./s\u001B[0m \u001B[33m0:01:22\u001B[0m / \u001B[36m0:00:23\u001B[0m Loss: 5.8789\n",
      "Training Epoch: 0 / 1  \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:01:22\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m-:--:--\u001B[0m             5.8789\n",
      "Training Batch: 10 / 13 \u001B[35m 77%\u001B[0m \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[31m0.13     \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m0:00:23\u001B[0m Loss: 5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 10 / 13 \u001B[35m 85%\u001B[0m \u001B[91m━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m0:00:15\u001B[0m Loss: 5.8789\n",
      "                                        \u001B[31mit./s    \u001B[0m                               Gradient overflow, skipping step 11\n",
      "Gradient overflow, skipping step 11Gradient overflow, skipping step 11\n",
      "\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing \n",
      "to 1048576\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 10 / 13 \u001B[35m 85%\u001B[0m \u001B[91m━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m0:00:15\u001B[0m Loss: 5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 11[0m                               \n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 10 / 13 \u001B[35m 85%\u001B[0m \u001B[91m━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:29\u001B[0m / \u001B[36m0:00:15\u001B[0m Loss: 5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 11 / 13 \u001B[35m 85%\u001B[0m \u001B[91m━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m0:00:15\u001B[0m Loss: 5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 11 / 13 \u001B[35m 92%\u001B[0m \u001B[91m━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m0:00:08\u001B[0m Loss: 5.8789\n",
      "                                        \u001B[31mit./s    \u001B[0m                               Gradient overflow, skipping step 12\n",
      "Gradient overflow, skipping step 12\n",
      "Gradient overflow, skipping step 12\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing \n",
      "to 524288\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 11 / 13 \u001B[35m 92%\u001B[0m \u001B[91m━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m0:00:08\u001B[0m Loss: 5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KGradient overflow, skipping step 12[0m                               \n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 11 / 13 \u001B[35m 92%\u001B[0m \u001B[91m━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:36\u001B[0m / \u001B[36m0:00:08\u001B[0m Loss: 5.8789\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m 92%\u001B[0m \u001B[91m━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:08\u001B[0m Loss: 5.8906\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:47\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:51\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 1 / 8 \u001B[35m 25%\u001B[0m \u001B[91m━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:07\u001B[0m / \u001B[36m0:00:22\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:54\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 2 / 8 \u001B[35m 38%\u001B[0m \u001B[91m━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:10\u001B[0m / \u001B[36m0:00:18\u001B[0m             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:01:58\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 3 / 8 \u001B[35m 50%\u001B[0m \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:14\u001B[0m / \u001B[36m0:00:15\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:01\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 4 / 8 \u001B[35m 62%\u001B[0m \u001B[91m━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:17\u001B[0m / \u001B[36m0:00:11\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:05\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 5 / 8 \u001B[35m 75%\u001B[0m \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:21\u001B[0m / \u001B[36m0:00:08\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:09\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 6 / 8 \u001B[35m 88%\u001B[0m \u001B[91m━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:24\u001B[0m / \u001B[36m0:00:04\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 7 / 8 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:28\u001B[0m / \u001B[36m0:00:00\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1m{\u001B[0mit./s    \u001B[0m                               \n",
      "  \u001B[1;34m\"ppl\"\u001B[0m: \u001B[1;36m361.75\u001B[0m\n",
      "\u001B[1m}\u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 7 / 8 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.28     \u001B[0m \u001B[33m0:00:28\u001B[0m / \u001B[36m0:00:00\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch:       \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:00:00\u001B[0m / \u001B[36m-:--:--\u001B[0m             /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformer\u001B[0m             \n",
      "s/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to \n",
      "control the generation length. This behaviour is deprecated and will be removed \n",
      "from the config in v5 of Transformers -- we recommend using `max_new_tokens` to \n",
      "control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:55:02]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=243962;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=529903;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:12\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:34\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:55:24]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=750800;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=681453;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:02:34\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:02:55\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 1 / 8 \u001B[35m 25%\u001B[0m \u001B[91m━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m21.21     \u001B[0m \u001B[33m0:00:42\u001B[0m / \u001B[36m0:02:08\u001B[0m             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:55:45]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=471029;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=617889;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:02:55\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 1 / 8 \u001B[35m 25%\u001B[0m \u001B[91m━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m21.21     \u001B[0m \u001B[33m0:00:42\u001B[0m / \u001B[36m0:02:08\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:03:16\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 2 / 8 \u001B[35m 38%\u001B[0m \u001B[91m━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m21.3     \u001B[0m \u001B[33m0:01:03\u001B[0m / \u001B[36m0:01:47\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:56:06]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=795667;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=844962;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:03:16\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 2 / 8 \u001B[35m 38%\u001B[0m \u001B[91m━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[31m21.3     \u001B[0m \u001B[33m0:01:03\u001B[0m / \u001B[36m0:01:47\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:03:38\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 3 / 8 \u001B[35m 50%\u001B[0m \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[31m21.3     \u001B[0m \u001B[33m0:01:25\u001B[0m / \u001B[36m0:01:26\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:56:27]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=291369;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=163032;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:03:38\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "                                        \u001B[31mit./s    \u001B[0m                               \n",
      "Evaluating Batch: 3 / 8 \u001B[35m 50%\u001B[0m \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[31m21.3     \u001B[0m \u001B[33m0:01:25\u001B[0m / \u001B[36m0:01:26\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:03:59\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 4 / 8 \u001B[35m 62%\u001B[0m \u001B[91m━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m21.27     \u001B[0m \u001B[33m0:01:46\u001B[0m / \u001B[36m0:01:04\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:56:49]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=97251;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=398382;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:03:59\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 4 / 8 \u001B[35m 62%\u001B[0m \u001B[91m━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━\u001B[0m \u001B[31m21.27     \u001B[0m \u001B[33m0:01:46\u001B[0m / \u001B[36m0:01:04\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:04:20\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 5 / 8 \u001B[35m 75%\u001B[0m \u001B[91m━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[31m21.31     \u001B[0m \u001B[33m0:02:07\u001B[0m / \u001B[36m0:00:43\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:57:10]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=633052;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=277370;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:04:20\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 5 / 8 \u001B[35m 75%\u001B[0m \u001B[91m━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[31m21.31     \u001B[0m \u001B[33m0:02:07\u001B[0m / \u001B[36m0:00:43\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:04:41\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 6 / 8 \u001B[35m 88%\u001B[0m \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━\u001B[0m \u001B[31m21.29     \u001B[0m \u001B[33m0:02:29\u001B[0m / \u001B[36m0:00:22\u001B[0m             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m[20:57:31]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m\u001B[32m' It provides a simple and efficient'\u001B[0m, \u001B[32m' It \u001B[0m   \u001B]8;id=562275;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001B\\\u001B[2mdecode.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=130889;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001B\\\u001B[2m51\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mprovides a simple and efficient'\u001B[0m, \u001B[32m' It provides\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32ma simple and efficient'\u001B[0m, \u001B[32m' It provides a simple\u001B[0m \u001B[2m            \u001B[0m\n",
      "\u001B[2;36m           \u001B[0m         \u001B[32mand efficient'\u001B[0m\u001B[1m]\u001B[0m                                 \u001B[2m            \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:04:41\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 6 / 8 \u001B[35m 88%\u001B[0m \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━\u001B[0m \u001B[31m21.29     \u001B[0m \u001B[33m0:02:29\u001B[0m / \u001B[36m0:00:22\u001B[0m             \n",
      "                                       \u001B[31ms/it.     \u001B[0m                               \u001B[2;36m[20:57:31]\u001B[0m\u001B[2;36m \u001B[0m\u001B[31mWARNING \u001B[0m Metri\u001B[1;92mc:dec\u001B[0mode returns \u001B[3;35mNone\u001B[0m when getting \u001B]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001B\\\u001B[2mmetric_wrapper.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001B\\\u001B[2m69\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         metric results.                         \u001B[2m                    \u001B[0m\n",
      "\u001B[2;36m[20:57:31]\u001B[0m\u001B[2;36m \u001B[0m\u001B[31mWARNING \u001B[0m Metri\u001B[1;92mc:dec\u001B[0mode returns \u001B[3;35mNone\u001B[0m when getting \u001B]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001B\\\u001B[2mmetric_wrapper.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001B\\\u001B[2m69\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         metric results.                         \u001B[2m                    \u001B[0m\n",
      "\u001B[2;36m[20:57:31]\u001B[0m\u001B[2;36m \u001B[0m\u001B[31mWARNING \u001B[0m Metri\u001B[1;92mc:dec\u001B[0mode returns \u001B[3;35mNone\u001B[0m when getting \u001B]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001B\\\u001B[2mmetric_wrapper.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001B\\\u001B[2m69\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         metric results.                         \u001B[2m                    \u001B[0m\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:05:03\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 7 / 8 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m21.28     \u001B[0m \u001B[33m0:02:50\u001B[0m / \u001B[36m0:00:00\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[2;36m          \u001B[0m\u001B[2;36m \u001B[0m\u001B[31mWARNING \u001B[0m Metri\u001B[1;92mc:dec\u001B[0mode returns \u001B[3;35mNone\u001B[0m when getting \u001B]8;id=659176;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001B\\\u001B[2mmetric_wrapper.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=648564;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001B\\\u001B[2m69\u001B[0m\u001B]8;;\u001B\\\n",
      "\u001B[2;36m           \u001B[0m         metric results.                         \u001B[2m                    \u001B[0m\n",
      "Training Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m-- it./s  \u001B[0m \u001B[33m0:05:03\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m0.14 it./s\u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "Evaluating Batch: 7 / 8 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━\u001B[0m \u001B[31m21.28     \u001B[0m \u001B[33m0:02:50\u001B[0m / \u001B[36m0:00:00\u001B[0m             \n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m  0%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:05:03\u001B[0m / \u001B[36m-:--:--\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Epoch: 0 / 1   \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m-- it./s \u001B[0m \u001B[33m0:05:03\u001B[0m / \u001B[36m0:00:00\u001B[0m             \n",
      "Training Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2KTraining Batch: 12 / 13 \u001B[35m100%\u001B[0m \u001B[90m━━━━━━━━━━\u001B[0m \u001B[31m0.14     \u001B[0m \u001B[33m0:01:44\u001B[0m / \u001B[36m0:00:00\u001B[0m Loss: 5.8906\n",
      "\u001B[2K\u001B[?25h2K                            \u001B[31mit./s    \u001B[0m                               \r"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --standalone example-tutorial-2-one-sentence-overfitting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88a1ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 &ensp; CoLLiE 的 Config 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511b591",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e940a922",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3 &ensp; CoLLiE 的 Trainer 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ce45c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70138f5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.4 &ensp; CoLLiE 的 Metric 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879b27d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2fde1c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.5 &ensp; CoLLiE 的 Monitor 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e882f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}