{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3b7df9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp; 2 &ensp; CoLLiE 的使用案例\n",
    "\n",
    "&emsp; &emsp; 2.1 &ensp; 案例：指令微调 MOSS\n",
    "\n",
    "&emsp; &emsp; 2.2 &ensp; CoLLiE 的 Config 模块\n",
    "\n",
    "&emsp; &emsp; 2.3 &ensp; CoLLiE 的 Monitor 模块\n",
    "\n",
    "&emsp; &emsp; 2.4 &ensp; CoLLiE 的 Evaluator 模块\n",
    "\n",
    "&emsp; &emsp; 2.5 &ensp; CoLLiE 的 Trainer 模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb9260",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. &ensp; CoLLiE 的使用案例\n",
    "\n",
    "### 2.1 &ensp; 案例：指令微调 MOSS\n",
    "\n",
    "&ensp; &ensp; 在上一章中，我们已经介绍了 CoLLiE 提出的背景、实现的功能 以及 包含的模块。\n",
    "\n",
    "&ensp; &ensp; 写个LOMO、ZeRO3、微调MOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf770de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2023-07-04 15:41:50,606] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-04 15:41:50,606] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-04 15:41:50,606] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-07-04 15:41:50,606] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "\n",
      "===================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      " \n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues ===================================BUG REPORT===================================\n",
      "\n",
      "and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "================================================================================\n",
      "===================================BUG REPORT=================================== \n",
      "================================================================================\n",
      "and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      " ================================================================================and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "\n",
      "================================================================================\n",
      "bin /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "bin bin/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so \n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "bin /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so\n",
      "\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.soCUDA SETUP: Highest compute capability among GPUs detected: 8.6CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "\n",
      "\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6CUDA SETUP: Detected CUDA version 117CUDA SETUP: Detected CUDA version 117\n",
      "\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /remote-home/xrliu/anaconda3/envs/collie did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "\n",
      "CUDA SETUP: Detected CUDA version 117CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "CUDA SETUP: CUDA runtime path found: /remote-home/xrliu/cudas/cuda-11.7/lib64/libcudart.so.11.0\n",
      "\n",
      "CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/bitsandbytes-0.39.1-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "Fetching 17 files: 100%|██████████████████████| 17/17 [00:00<00:00, 7848.45it/s]\n",
      "Fetching 17 files: 100%|█████████████████████| 17/17 [00:00<00:00, 12400.55it/s]\n",
      "[2023-07-04 15:42:45,957] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-04 15:42:45,957] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-04 15:42:45,957] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-04 15:42:45,958] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "Fetching 17 files: 100%|█████████████████████| 17/17 [00:00<00:00, 21177.06it/s]\n",
      "[2023-07-04 15:42:46,261] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-04 15:42:46,261] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "Fetching 17 files: 100%|██████████████████████| 17/17 [00:00<00:00, 8602.14it/s]\n",
      "[2023-07-04 15:42:46,349] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-07-04 15:42:46,349] [INFO] [comm.py:594:init_distributed] cdb=None\n",
      "[2023-07-04 15:42:46,349] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2023-07-04 15:43:00,254] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 16.72B parameters\n",
      "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m0.11 it./s\u001b[0m \u001b[33m0:00:39\u001b[0m / \u001b[36m0:00:00\u001b[0m  \u001b[36m0:00:08\u001b[0m m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m /  \u001b[2;36m[15:44:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m The world size is not equal to the product of \u001b]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py#262\u001b\\\u001b[2m262\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         the parallel sizes set.\u001b[1;36m4\u001b[0m != \u001b[1;36m1\u001b[0m * \u001b[1;36m1\u001b[0m * \u001b[1;36m1\u001b[0m.        \u001b[2m              \u001b[0m\n",
      "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Set dp_size to \u001b[1;36m4\u001b[0m.                             \u001b]8;id=571858;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=91161;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/controller/trainer.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
      "[2023-07-04 15:44:10,715] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-04 15:44:10,716] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-04 15:44:10,859] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2023-07-04 15:44:10,860] [INFO] [utils.py:786:see_memory_usage] MA 7.93 GB         Max_MA 11.3 GB         CA 13.06 GB         Max_CA 13 GB \n",
      "[2023-07-04 15:44:10,860] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.67 GB, percent = 4.5%\n",
      "Parameter Offload: Total persistent parameters: 1474560 in 138 params\n",
      "[2023-07-04 15:44:10,970] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2023-07-04 15:44:10,971] [INFO] [utils.py:786:see_memory_usage] MA 7.93 GB         Max_MA 7.93 GB         CA 13.06 GB         Max_CA 13 GB \n",
      "[2023-07-04 15:44:10,971] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.67 GB, percent = 4.5%\n",
      "[2023-07-04 15:44:10,972] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbeaffc8130>\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-07-04 15:44:10,973] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   fp16_auto_cast ............... False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-04 15:44:10,974] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-07-04 15:44:10,993] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-04 15:44:10,994] [INFO] [config.py:964:print]   steps_per_print .............. 10\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   train_batch_size ............. 8\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  2\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   world_size ................... 4\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. False\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:964:print]   zero_optimization_stage ...... 3\n",
      "[2023-07-04 15:44:10,995] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true, \n",
      "    \"zero_force_ds_cpu_optimizer\": false, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }\n",
      "    }, \n",
      "    \"train_micro_batch_size_per_gpu\": 2, \n",
      "    \"gradient_accumulation_steps\": 1\n",
      "}\n",
      "\u001b[2KTraining Epoch   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch: 0 / 13 \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m Gradient overflow, skipping step 0\n",
      "Gradient overflow, skipping step 0\n",
      "Gradient overflow, skipping step 0\n",
      "\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, \n",
      "reducing to 2147483648\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n",
      "\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:00\u001b[0m / \u001b[36m-:--:--\u001b[0m \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:15\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:15\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 0 / 13 \u001b[35m  8%\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:15\u001b[0m / \u001b[36m-:--:--\u001b[0m Loss: 5.8906Gradient overflow, skipping step 1\n",
      "Gradient overflow, skipping step 1\n",
      "Gradient overflow, skipping step 1\n",
      "\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, \n",
      "reducing to 1073741824\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:15\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 1m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:15\u001b[0m / \u001b[36m-:--:--\u001b[0m Loss: 5.8906\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:15\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[31m-- it./s\u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 1 / 13 \u001b[35m 15%\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m0:02:07\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 2\n",
      "Gradient overflow, skipping step 2\n",
      "Gradient overflow, skipping step 2\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, \n",
      "reducing to 536870912\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 1 / 13 \u001b[35m 15%\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m0:02:07\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 2\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 1 / 13 \u001b[35m 15%\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:27\u001b[0m / \u001b[36m0:02:07\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 2 / 13 \u001b[35m 15%\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m0:02:07\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 2 / 13 \u001b[35m 23%\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m0:01:55\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 3\n",
      "Gradient overflow, skipping step 3\n",
      "Gradient overflow, skipping step 3\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing\n",
      "to 268435456\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 2 / 13 \u001b[35m 23%\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m0:01:55\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 3\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 2 / 13 \u001b[35m 23%\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:38\u001b[0m / \u001b[36m0:01:55\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 3 / 13 \u001b[35m 23%\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m0:01:55\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 3 / 13 \u001b[35m 31%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m0:01:44\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 4\n",
      "Gradient overflow, skipping step 4\n",
      "Gradient overflow, skipping step 4\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing\n",
      "to 134217728\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 3 / 13 \u001b[35m 31%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m0:01:44\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 4\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 3 / 13 \u001b[35m 31%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:00:50\u001b[0m / \u001b[36m0:01:44\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 4 / 13 \u001b[35m 31%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m0:01:44\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 4 / 13 \u001b[35m 38%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m0:01:32\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 5\n",
      "Gradient overflow, skipping step 5\n",
      "Gradient overflow, skipping step 5\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing\n",
      "to 67108864\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 4 / 13 \u001b[35m 38%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m0:01:32\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 5\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 4 / 13 \u001b[35m 38%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:01\u001b[0m / \u001b[36m0:01:32\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:13\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 5 / 13 \u001b[35m 38%\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:12\u001b[0m / \u001b[36m0:01:32\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:13\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 5 / 13 \u001b[35m 46%\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:12\u001b[0m / \u001b[36m0:01:21\u001b[0m Loss: 5.8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 6Gradient overflow, skipping step 6\n",
      "\n",
      "Gradient overflow, skipping step 6\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing \n",
      "to 33554432\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:13\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 5 / 13 \u001b[35m 46%\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:12\u001b[0m / \u001b[36m0:01:21\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 6\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:13\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 5 / 13 \u001b[35m 46%\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:12\u001b[0m / \u001b[36m0:01:21\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 6 / 13 \u001b[35m 46%\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m0:01:21\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 6 / 13 \u001b[35m 54%\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m0:01:09\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 7\n",
      "Gradient overflow, skipping step 7\n",
      "Gradient overflow, skipping step 7\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing \n",
      "to 16777216\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 6 / 13 \u001b[35m 54%\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m0:01:09\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 7\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 6 / 13 \u001b[35m 54%\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:24\u001b[0m / \u001b[36m0:01:09\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 7 / 13 \u001b[35m 54%\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[31m11.44     \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m0:01:09\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 7 / 13 \u001b[35m 62%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m0:00:58\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 8\n",
      "Gradient overflow, skipping step 8\n",
      "Gradient overflow, skipping step 8\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing \n",
      "to 8388608\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 7 / 13 \u001b[35m 62%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m0:00:58\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 8\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 7 / 13 \u001b[35m 62%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:35\u001b[0m / \u001b[36m0:00:58\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 8 / 13 \u001b[35m 62%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m0:00:58\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 8 / 13 \u001b[35m 69%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m0:00:46\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 9\n",
      "Gradient overflow, skipping step 9\n",
      "Gradient overflow, skipping step 9\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing \n",
      "to 4194304\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 8 / 13 \u001b[35m 69%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m0:00:46\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 9\u001b[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 8 / 13 \u001b[35m 69%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:47\u001b[0m / \u001b[36m0:00:46\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 9 / 13 \u001b[35m 69%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m0:00:46\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 9 / 13 \u001b[35m 77%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m0:00:35\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 10\n",
      "Gradient overflow, skipping step 10\n",
      "Gradient overflow, skipping step 10\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing \n",
      "to 2097152\n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 9 / 13 \u001b[35m 77%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m0:00:35\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 10[0m                               \n",
      "Training Epoch: 0 / 1  \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 9 / 13 \u001b[35m 77%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:01:58\u001b[0m / \u001b[36m0:00:35\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 10 / 13 \u001b[35m 77%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m0:00:35\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 10 / 13 \u001b[35m 85%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m0:00:23\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 11\n",
      "Gradient overflow, skipping step 11\n",
      "Gradient overflow, skipping step 11\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing \n",
      "to 1048576\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 10 / 13 \u001b[35m 85%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m0:00:23\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 11[0m                               \n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 10 / 13 \u001b[35m 85%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:10\u001b[0m / \u001b[36m0:00:23\u001b[0m Loss: 5.8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 11 / 13 \u001b[35m 85%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m0:00:23\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 11 / 13 \u001b[35m 92%\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m0:00:12\u001b[0m Loss: 5.8906\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               Gradient overflow, skipping step 12\n",
      "Gradient overflow, skipping step 12\n",
      "Gradient overflow, skipping step 12\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K[LOMO] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing \n",
      "to 524288\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 11 / 13 \u001b[35m 92%\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m0:00:12\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KGradient overflow, skipping step 12[0m                               \n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 11 / 13 \u001b[35m 92%\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:21\u001b[0m / \u001b[36m0:00:12\u001b[0m Loss: 5.8906\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m 92%\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[31m11.45     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:12\u001b[0m Loss: 5.8711\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:44\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:50\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:02:55\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:01\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:06\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:12\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             5h\u001b[?25h\n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 7 / 8 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m0.18 it./s\u001b[0m \u001b[33m0:00:44\u001b[0m / \u001b[36m0:00:00\u001b[0m             /remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1m{\u001b[0m\n",
      "  \u001b[1;34m\"ppl\"\u001b[0m: \u001b[1;36m354.75\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K/remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/transformer\u001b[0m             \n",
      "s/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to \n",
      "control the generation length. This behaviour is deprecated and will be removed \n",
      "from the config in v5 of Transformers -- we recommend using `max_new_tokens` to \n",
      "control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:48:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=243962;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=529903;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:18\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:51\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:48:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=750800;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=681453;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:03:51\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:04:24\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 1 / 8 \u001b[35m 25%\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m33.41     \u001b[0m \u001b[33m0:01:06\u001b[0m / \u001b[36m0:03:21\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:49:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=471029;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=617889;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:04:24\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 1 / 8 \u001b[35m 25%\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[31m33.41     \u001b[0m \u001b[33m0:01:06\u001b[0m / \u001b[36m0:03:21\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:04:58\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:49:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=795667;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=844962;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:04:58\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:05:31\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 3 / 8 \u001b[35m 50%\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[31m33.39     \u001b[0m \u001b[33m0:02:13\u001b[0m / \u001b[36m0:02:14\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:50:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=291369;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=163032;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:05:31\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 3 / 8 \u001b[35m 50%\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[31m33.39     \u001b[0m \u001b[33m0:02:13\u001b[0m / \u001b[36m0:02:14\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:06:05\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:50:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=97251;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=398382;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:06:05\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:06:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 5 / 8 \u001b[35m 75%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[31m33.39     \u001b[0m \u001b[33m0:03:20\u001b[0m / \u001b[36m0:01:07\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:51:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=633052;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=277370;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:06:38\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 5 / 8 \u001b[35m 75%\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[31m33.39     \u001b[0m \u001b[33m0:03:20\u001b[0m / \u001b[36m0:01:07\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:07:11\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 6 / 8 \u001b[35m 88%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[31m33.39     \u001b[0m \u001b[33m0:03:53\u001b[0m / \u001b[36m0:00:34\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m[15:51:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m' It provides a simple and efficient'\u001b[0m, \u001b[32m' It \u001b[0m   \u001b]8;id=562275;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py\u001b\\\u001b[2mdecode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130889;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/metrics/decode.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mprovides a simple and efficient'\u001b[0m, \u001b[32m' It provides\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32ma simple and efficient'\u001b[0m, \u001b[32m' It provides a simple\u001b[0m \u001b[2m            \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         \u001b[32mand efficient'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m            \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:07:11\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 6 / 8 \u001b[35m 88%\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[31m33.39     \u001b[0m \u001b[33m0:03:53\u001b[0m / \u001b[36m0:00:34\u001b[0m             \n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \u001b[2;36m[15:51:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Metri\u001b[1;92mc:dec\u001b[0mode returns \u001b[3;35mNone\u001b[0m when getting \u001b]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001b\\\u001b[2mmetric_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001b\\\u001b[2m69\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         metric results.                         \u001b[2m                    \u001b[0m\n",
      "\u001b[2;36m[15:51:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Metri\u001b[1;92mc:dec\u001b[0mode returns \u001b[3;35mNone\u001b[0m when getting \u001b]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001b\\\u001b[2mmetric_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001b\\\u001b[2m69\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         metric results.                         \u001b[2m                    \u001b[0m\n",
      "\u001b[2;36m[15:51:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Metri\u001b[1;92mc:dec\u001b[0mode returns \u001b[3;35mNone\u001b[0m when getting \u001b]8;id=234053;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001b\\\u001b[2mmetric_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146316;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001b\\\u001b[2m69\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         metric results.                         \u001b[2m                    \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:07:45\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 7 / 8 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m33.38     \u001b[0m \u001b[33m0:04:27\u001b[0m / \u001b[36m0:00:00\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Metri\u001b[1;92mc:dec\u001b[0mode returns \u001b[3;35mNone\u001b[0m when getting \u001b]8;id=659176;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py\u001b\\\u001b[2mmetric_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=648564;file:///remote-home/xrliu/anaconda3/envs/collie/lib/python3.9/site-packages/collie-1.0.1-py3.9.egg/collie/utils/metric_wrapper.py#69\u001b\\\u001b[2m69\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         metric results.                         \u001b[2m                    \u001b[0m\n",
      "Training Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:07:45\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "                                       \u001b[31ms/it.     \u001b[0m                               \n",
      "Evaluating Batch: 7 / 8 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m33.38     \u001b[0m \u001b[33m0:04:27\u001b[0m / \u001b[36m0:00:00\u001b[0m             \n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m  0%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:07:45\u001b[0m / \u001b[36m-:--:--\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Epoch: 0 / 1   \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m-- it./s  \u001b[0m \u001b[33m0:07:45\u001b[0m / \u001b[36m0:00:00\u001b[0m             \n",
      "Training Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTraining Batch: 12 / 13 \u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━\u001b[0m \u001b[31m11.46     \u001b[0m \u001b[33m0:02:33\u001b[0m / \u001b[36m0:00:00\u001b[0m Loss: 5.8711\n",
      "\u001b[2K\u001b[?25h2K                           \u001b[31ms/it.     \u001b[0m                               \r"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --standalone example-tutorial-2-one-sentence-overfitting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88a1ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 &ensp; CoLLiE 的 Config 模块\n",
    "\n",
    "config参数列表\n",
    "\n",
    "| 名称 | 类型 | 默认值 | 描述 |\n",
    "|:----|:----:|:----:|:----|\n",
    "| seed | int | 42 | Random seed that will be set at the beginning of training | \n",
    "| pp_size | int | 1 | Pipeline parallelism degree. | \n",
    "| tp_size | int | 1 | Tensor parallelism degree. | \n",
    "| dp_size | int | 1 | Data parallelism degree | \n",
    "| pp_partition_method | str | 'parameters' | Partition method for pipeline parallelism. Default is 'parameters'. | \n",
    "| train_epochs | int | 100 | Number of training epochs. | \n",
    "| eval_per_n_steps | int | 0 | Evaluate every n steps. | \n",
    "| eval_per_n_epochs | int | 0 | Evaluate every n epochs. | \n",
    "| train_micro_batch_size | int | 1 | Batch size (one step) for training. | \n",
    "| gradient_accumulation_steps | int | 1 | Number of gradient accumulation steps. | \n",
    "| eval_batch_size | int | 1 | Batch size for evaluation. | \n",
    "| checkpointing | bool | True | Whether to use activation checkpointing.\n",
    "| use_flash | bool | True | Whether to use flash attention.\n",
    "| dropout | float | 0.0 | Dropout probability. | \n",
    "| initization_method | str | \"none\" | Initialization method. Possible values are 'none', 'normal', 'xavier_normal', 'xavier_uniform', 'kaiming_normal', 'kaiming_uniform', 'orthogonal', 'sparse', 'eye', 'dirac'. Default is 'none'. | \n",
    "| initization_method_params | dict | None | Parameters for initialization method.\n",
    "| low_cpu_mem_usage | bool | True | Tries to not use more than 1x model size in CPU memory (including peak memory) while loading the model. | \n",
    "| ds_config | Union[str, dict] | \"\" | DeepSpeed configuration file. | \n",
    "| model_config | PretrainedConfig | PretrainedConfig() | Model configuration. | \n",
    "| peft_config | PeftConfig | PeftConfig() | PEFT configuration. | \n",
    "| quantization_config | BitsAndBytesConfig | BitsAndBytesConfig() | Configuration parameters for the `bitsandbytes` library | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511b591",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collie.config import CollieConfig\n",
    "\n",
    "pretrained_model = \"fnlp/moss-moon-003-sft\"  \n",
    "\n",
    "config = CollieConfig.from_pretrained(pretrained_model, trust_remote_code=True)\n",
    "config.tp_size = 1\n",
    "config.dp_size = 1\n",
    "config.pp_size = 1\n",
    "config.train_epochs = 1\n",
    "config.eval_per_n_steps = 0\n",
    "config.eval_per_n_epochs = 1 \n",
    "config.train_micro_batch_size = 2\n",
    "config.eval_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fde1c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3 &ensp; CoLLiE 的 Monitor 模块\n",
    "\n",
    "monitor模块列表\n",
    "\n",
    "| 名称 | 描述 |\n",
    "|:----|:----|\n",
    "| BaseMonitor | 用于记录模型训练过程中的统计信息 |\n",
    "| StepTimeMonitor | 用来记录每个step的时间 |\n",
    "| NetworkIOMonitor | 用来记录每个step的网络带宽情况 |\n",
    "| DiskIOMonitor | 用来记录每个step的硬盘读写情况 |\n",
    "| TGSMonitor | 用来记录每秒每张 GPU 可训练的 token 数 (token / s / GPU) |\n",
    "| CPUMemoryMonitor | 用来记录每个step的CPU内存占用 |\n",
    "| MemoryMonitor | 用来记录每个step的内存占用 |\n",
    "| LossMonitor | 用来记录每个step的loss |\n",
    "| EvalMonitor | 用来记录每个step的eval结果，仅支持 int 和 float 类型的结果 |\n",
    "| LRMonitor | 用来记录每个step的learning rate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e882f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collie.utils.monitor import StepTimeMonitor, TGSMonitor, MemoryMonitor, LossMonitor, EvalMonitor\n",
    "\n",
    "monitors = [\n",
    "    StepTimeMonitor(config),\n",
    "    TGSMonitor(config),\n",
    "    MemoryMonitor(config),\n",
    "    LossMonitor(config),\n",
    "    EvalMonitor(config)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70138f5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.4 &ensp; CoLLiE 的 Evaluator 模块\n",
    "\n",
    "evaluator模块列表\n",
    "\n",
    "| 名称 | 描述 |\n",
    "|:----|:----|\n",
    "| Evaluator | | \n",
    "| EvaluatorForPerplexity | | \n",
    "| EvaluatorForClassfication | | \n",
    "| EvaluatorForGeneration | | \n",
    "\n",
    "metric模块列表\n",
    "\n",
    "| 名称 | 描述 |\n",
    "|:----|:----|\n",
    "| BaseMetric | |\n",
    "| DecodeMetric | |\n",
    "| AccuracyMetric | |\n",
    "| PPLMetric | |\n",
    "| BleuMetric | |\n",
    "| RougeMetric | |\n",
    "| ClassifyFPreRecMetric | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ce45c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collie.controller.evaluator import EvaluatorForPerplexity, EvaluatorForGeneration\n",
    "\n",
    "from collie.metrics import PPLMetric, DecodeMetric\n",
    "\n",
    "evaluator_ppl = EvaluatorForPerplexity(\n",
    "    model=model, config=config, dataset=eval_dataset,\n",
    "    monitors=[EvalMonitor(config), ], metrics={'ppl': PPLMetric(), }\n",
    ")\n",
    "\n",
    "evaluator_decode = EvaluatorForGeneration(\n",
    "    model=model, config=config, tokenizer=tokenizer, dataset=eval_dataset,\n",
    "    monitors=[EvalMonitor(config), ], metrics={'decode': DecodeMetric(), }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940a922",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.5 &ensp; CoLLiE 的 Trainer 模块\n",
    "\n",
    "trainer参数列表\n",
    "\n",
    "| 名称 | 类型 | 默认值 | 描述 |\n",
    "|:----|:----:|:----:|:----|\n",
    "| model | torch.nn.Module | | | \n",
    "| config | CollieConfig | | | \n",
    "| tokenizer | PreTrainedTokenizerBase | None | | \n",
    "| loss_fn | Callable | GPTLMLoss() | | \n",
    "| train_fn | Callable | None | | \n",
    "| eval_fn | Callable | None | | \n",
    "| optimizer | torch.optim.Optimizer | None | | \n",
    "| lr_scheduler | LRScheduler, DeepSpeedSchedulerCallable | None | | \n",
    "| train_dataset | torch.utils.data.Dataset | None | | \n",
    "| eval_dataset | torch.utils.data.Dataset | None | | \n",
    "| callbacks | Callback, List[Callback] | None | | \n",
    "| train_dataset_collate_fn | Callable | ColliePadder() | | \n",
    "| eval_dataset_collate_fn | Callable | ColliePadder(padding_left=True) | | \n",
    "| data_provider | BaseProvider | None | | \n",
    "| monitors | BaseMonitor | [] | | \n",
    "| metrics | Dict | None | | \n",
    "| evaluators | List | None | | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879b27d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collie.controller.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,config=config,train_dataset=train_dataset,\n",
    "    loss_fn=GPTLMLoss(-100),optimizer=optimizer,\n",
    "    monitors=monitors, evaluators=[evaluator_ppl, evaluator_decode]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
